---
title: "Examen Parcial Estadística Computacional"
author: "Omar Díaz Landa"
date: "Tuesday, October 07, 2014"
output: html_document
---


<style>
  .caja {
    background-color:mistyrose;
    padding:5px;
  }
</style>

</br>

```{r, echo=FALSE, message=FALSE, error=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(plyr)
library(boot)
library(bootstrap)
#library(xlsx)
```


## Pregunta 1

Una caja contiene 10 pares de aretes, si se seleccionan 8 aretes, cuál es 
la probabilidad de:

#### + No se seleccione ningún par

Para conocer la probabilidad de que no se seleccione ningún par, es necesario en primera instancia crear una base de datos que represente nuestro espacio muestral. La base creada es la siguiente:
```{r,eval=FALSE}
arete = c('A1','A2','B1','B2','C1','C2','D1','D2','E1','E2',
           'F1','F2','G1','G2','H1','H2','I1','I2','J1','J2')
```
Posteriormente, se pretende simular el evento una gran cantidad de veces, de tal manera que se pueda observar la probabilidad a la que se converge. Para ello, se ha creado la siguiente función, la cual se ejecutará un total de $50000$ veces.

En dicha función se tomará una muestra sin reemplazo de los los 20 aretes disponibles y de la muestra seleccionada se observará y registrará si hay algún par en ella. Finalmente se calcularán casos favorables entre casos totales para conocer la probabilidad de interés.


```{r,echo=TRUE,eval=FALSE}
nopar<-function(){
  muestra <- sample_n(as.data.frame(arete),size=8,replace=FALSE)
  letras <- substr(muestra$arete,1,1)
  par<-length(unique(letras))<nrow(muestra)
  return(par)
}


B=50000
nopar<-rdply(B,nopar)
1-(sum(nopar$V1)/B)
```

Por lo tanto, la probabiliad de no seleccionar un par es de $0.0940$.

#### + Se seleccione exactamente un par completo

De manera similar al caso anterior, es posible simular la probabiliadd de que se seleccione exactametne un par completo, así pues, en este caso se tomará la muestra y se revisarán cuantos aretes de cada clase se tienen, si nos sobra un solo arete es por que hay un par en la muestra seleccionada. Por lo tanto, la función mosstrada a continuación evalua si el número de aretes distintos seleccionados son 7.


```{r,echo=TRUE,eval=FALSE}
expar<-function(){
  muestra <- sample_n(as.data.frame(arete),size=8,replace=FALSE)
  letras <- substr(muestra$arete,1,1)
  par<-length(unique(letras))==(length(letras)-1)
  return(par)
}

E=50000
nop<-rdply(E,expar)
(sum(nop$V1)/E)
```
 
 Por lo tanto, la probabilidad de seleccionar exactamente un par es de $0.4294$.
 
 
 
## Pregunta 2
 
 A y B juegan una serie de juegos. En cada juego A gana con probabilidad de $0.4$ y B con probabilidad de $0.6$ (independiente de lo ocurrido en los otros juegos). Paran de jugar cuando el número total de juegos ganados de un jugador es dos juegos más que el total de juegos ganados por el otro jugador:
 
#### + Encuentra la probabilidad de que se jueguen cuatro juegos en total
 
 Estos resultados se pueden encontrar de manera analítica usando teoría de probabilidad, sin embargo, el método por simulación presenta un enfoque distinto para resolver la misma pregunta. Al igual que en la pregunta anterior basta con crear una función que represente el evento que se desea conocer, posteriormente, observarlo un número suficiente de veces y finalmente hacer la razón de casos favorables entre casos totales.
 


```{r,echo=TRUE,eval=FALSE}

juego<-function(){
  A<-0
  B<-0
  k<-0
  
  acabo=FALSE
  while(!acabo){
  u=runif(1)
  if(u<.4){
    A=A+1
  }else{
    B=B+1
  }
  
  if(A==B+2 | B==A+2){
    acabo=TRUE
  }
  k<-k+1
}
return(k)  
}

E=50000
juada<-rdply(E,juego)
length(which(juada$V1==4))/E
``` 
 
  En particular, para generar un evento nos interesa tener una mendia que nos indique si gana el jugador A o el jugador B, por esta razón se crea una variable aleatoria uniforme tal que si es menor a $0.4$ le asigna una victoria a el jugadro A y de lo contrario al jugadro B, la condición de paro tal y como se describe en el planteamiento del problema consiste en observar si alguno de los dos le lleva dos victorias de ventaja a su oponente. Posteriormente se observa $50000$ veces este experimento para otorgarnos la probabilidad de $0.2478$.
  
#### + Encuentra la probabilidad de que A gane la serie

Si la probabilidad que nos interesa calcular es que el jugador A gane la serie, basta con modificar el criterio de paro, pues ahora nos interesa finalizar el evento únicamente cuando A tiene dos victorias de ventaja sobre B.


```{r,echo=TRUE,eval=FALSE}


juego_a<-function(){
  A<-0
  B<-0
  k<-0
  
  acabo=FALSE
  while(!acabo){
    u=runif(1)
    if(u<.4){
      A=A+1
    }else{
      B=B+1
    }
    
    if(A==B+2){
      k=1
      acabo=TRUE
    }else{
      if(B==A+2){
        acabo=TRUE
        K=0
      }
    }
  }
  return(k)  
}

E=50000
juada<-rdply(E,juego_a)
sum(juada$V1)/E

``` 

 La probabilidad obtenida a partir de la simulación es de $0.3074$.
 
## Pregunta 3 

La base de datos amis (publicada por G. Amis) contiene información de velocidades de coches en millas por hora, las mediciones se realizaron en carreteras de Cambridgeshire, y para cada carretera se realizan mediciones en dos sitios. Mas aún, las mediciones se realizaron en dos ocasiones, antes y después de que se instalara una señal de alerta (de disminución de velocidad), esta señal se erigió únicamente en uno de los dos sitios de cada carretera.

La cantidad de interés es el cambio medio relativo de velocidad en el cuantil $0.85$. Se eligió esta cantidad por que el objetivo de la señal de alerta es disminuir la velocidad de los conductores más veloces.

Variables:
  + Speed.- Velocidad de los autos en mph
  + Period.- periodo en que se hicieron las mediciones, 1 indica antes de la señal y 2 cuando ya habia señal
  + Pair.- Carretera en que se hizo la medición 

#### a) ¿Las observaciones conforman una muestra aleatoria?


La muestra no es aleatoria, debido a que la base de datos se obtuvo a través de un diseño de experimentos. La varaible period indica si se hizo la medicion antes y despues, para la variable warning se tiene valroes 1 y 2 para referir a los valroes de carreteras y la variable period corresponde a las 11 carreteras. Por cada combinación de valores de las variables se tomaron 100 datos por loq ue se tienen 400 medicones de velocidad por cada carretera. A esto se le conoce como un diseño de experimentos k-factorial.

#### b) El estadístico de interés se puede escribir como

$$\eta=\frac{1}{m}[(\eta_{a1}-\eta_{b1})-(\eta_{a0}-\eta_{b0})]$$ 

#### donde  $\eta_{a1}$, $\eta_{b1}$ corresponden a los cuartiles $0.85$ de la distribución de velocidad en los sitios en los que se colocó la señal de alerta, ($a$ corresponde a las mediciones antes de la señal y $b$ después) y $\eta_{a0}$, $\eta_{b0}$ son los correspondientes para los sitios sin alerta, $m$ denota el número de carreteras. Calcula el estimador _plug-in_ de $\eta$.


Para poder conocer el estimador _plug-in_ de $\eta$, es necesario poder conocer los percentiles $0.85$ de la distribuicón de velocidad del sitio 1 y 2 antes y después de la señal. Es decir, $\eta_{11}$ y $\eta_{21}$ representan el percentil $0.85$ del sitio uno y dos después de la señal. De manera análoga, $\eta_{12}$ y $\eta_{22}$ son el percentil $0.85$ del sitio 1 y 2 antes de la señal respectivamente.

```{r,eval=FALSE}
amis <- read.csv("amis.csv")
head(amis)

caso11 <- subset(amis, amis$warning == 1 & amis$period ==2)
eta11 <- quantile(caso11$speed,0.85)

caso21 <- subset(amis, amis$warning == 2 & amis$period ==2)
eta21 <- quantile(caso21$speed,0.85)

caso12 <- subset(amis, amis$warning == 1 & amis$period ==1)
eta12 <- quantile(caso12$speed,0.85)

caso22 <- subset(amis, amis$warning == 2 & amis$period ==1)
eta22 <- quantile(caso22$speed,0.85)

eta = (1/11)*((as.numeric(eta11) - as.numeric(eta21)) - (as.numeric(eta12) - as.numeric(eta22)))
```

 Una vez obtenidos dichos valores, es posible calcular el valor del estimador _plug-in_ de $\eta$:
 
 $$\eta=-0.09090909$$
 
#### c) Genera $B=3000$ replicaciones bootstrap de $\eta$ y realiza un histograma.

Las replicaciones bootstrap son de utilidad ya que permiten determinar que tan preciso es un estadístico, así como poder generar intervalos de confianza. Para ello debemos seleccionar $B$ muestras bootsrap independientes y calcular el estimador correspondiente a cada muestra. Esto nos permitirá conocer la distribución del estimador basado en los datos. tal y como se muestra en la siguiente figura:

```{r,eval=FALSE}

boot <- function(caso11,caso21,caso12,caso22){ 
  n <- nrow(aux11)
  muestra_boot_caso11 <- sample_n(caso11, size = n, replace = TRUE)
  muestra_boot_caso21 <- sample_n(caso21, size = n, replace = TRUE)
  muestra_boot_caso12 <- sample_n(caso12, size = n, replace = TRUE)
  muestra_boot_caso22 <- sample_n(caso22, size = n, replace = TRUE)
  
  eta11 <- quantile(muestra_boot_caso11$speed,0.85)
  eta21 <- quantile(muestra_boot_caso21$speed,0.85)
  eta12 <- quantile(muestra_boot_caso12$speed,0.85)
  eta22 <- quantile(muestra_boot_caso22$speed,0.85)
  
  eta = (1/11)*((as.numeric(eta11) - as.numeric(eta21)) - (as.numeric(eta12) - as.numeric(eta22)))
  
  return(eta)
  
}

B=3000
thetas_boot <- rdply(B, boot(caso11,caso21,caso12,caso22))

ggplot(thetas_boot, aes(x = V1)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.015, fill = "darkgray") + 
  geom_vline(aes(xintercept = mean(V1), color = "red"))
```


<center>![histograma3c](C:\Users\Administrador\Desktop\parcialEC\imagenes\histograma3c.png)


#### d) Genera intervalos de confianza usando la aproximación normal y percentiles. Comparalos y en caso de encontrar diferencias explica a que se debe.

Al conocer la distribución del estimador es posible conocer los intevalos de confiaza tanto normales como por percentiles. Al observar la gráfica, es posible observar que es simétrica por lo que es de esperarse que dichos intervalos sean similares.

```{r,eval=FALSE}

li_normal <- round(eta - 1.96 * sd(thetas_boot$V1), 2)
ls_normal <- round(eta + 1.96 * sd(thetas_boot$V1), 2)
c(li_normal,ls_normal) #intervalos normales


# percentiles
ls_per <- round(quantile((thetas_boot$V1), prob = 0.975), 2)
li_per <- round(quantile((thetas_boot$V1), prob = 0.025), 2)
c(li_per,ls_per)
```

$$\mbox{IC Normal} = (-0.21,0.09)$$
$$\mbox{IC Percentiles} = (-0.21,0.09)$$

Ambos intervalos son similares aunque con gran varianza, esto se debe a que hay casos con muy pocas observaciones y otros más poblados.


## Pregunta 4

Recuerda que una variable aleatoria $X$ tiene una distribuciÃ³n geométrica con parámetro $p$ si
$$p_X(i) = P(X=i)=pq^{i-1}$$
para $i=1,2,...$  y donde $q=1-p$. 

Notemos que
$$\sum_{i=1}^{j-1}P(X=i)=1-P(X\geq j-1)$$
$$=1 - q^{j-1}$$
para $j\geq 1$.
por lo que podemos generar un valor de $X$ generando un número aleatorio $U$ y seleccionando $j$ tal que
$$1-q^{j-1} \leq U \leq 1-q^j$$

Esto es, podemos definir $X$ como:
$$X=min\{j : (1-p)^j < 1-U\}$$
usando que el logaritmo es una función monótona (i.e. $a<b$ implica $log(a)<log(b)$) obtenemos que podemos expresar $X$ como 
$$X=min\big\{j : j \cdot log(q) < log(1-U)\big\}$$
$$=min\big\{j : j > log(U)/log(q)\big\}$$
entonces
$$X= int\bigg(\frac{log(U)}{log(q)}\bigg)+1$$

es geométrica con parámetro $p$.

Ahora, sea $X$ el número de lanzamientos de una moneda que se requieren para alcanzar $r$ éxito (soles) cuando cada lanzamiento es independiente,  $X$ tiene una distribución binomial negativa.

Una variable aleatoria $X$ tiene distribución binomial negativa con parámetros $(r,p)$ donde $r$ es un entero positivo y $0<p<r$ si
$$P(X=j)=\frac{(j-1)!}{(j-r)!(r-1)!}p^r(1-p)^{j-r}.$$

#### a) Recuerda la distribución geométrica ¿cuál es a relación entre la variable aleatoria binomial negativa y la geométrica?

La relación que guardan estas dos variables aleatorias es que la suma de $r$ geométricas independientes con parámetro $p$, se distribuye binomial negativa con parámetros $r, p$.

#### b) Utiliza el procedimiento descrito para generar observaciones de una variable aleatoria con distribución geométrica y la relación entre la geométrica y la binomial negativa para generar simulaciones de una variable aleatoria con distribución binomial negativa (parámetro p = 0.4, r = 20). Utiliza la semilla 221285 (en R usa set.seed) y reporta las primeras 10 simulaciones obtenidas.

A partir del procedimiento descrito es posible generar observaciones de uan variable aleatoria con distribucion gemoétrica, es decir que para $p=0.4$ se tiene que

$$g_i=int\left ( \frac{ln(U_{(0,1)})}{ln(1-p)}\right )+1$$

Con este algoritmo es posible generar tantas variables geométricas como se desee y se puede comprobar a través de un histograma.


```{r,eval=FALSE}
set.seed(221285)

geom<-function(p){
  g<-floor((log(runif(1))/log(1-p)))+1
  return(g)
}
geometricas<-rdply(100000,geom(.4))
ggplot(geometricas,aes(x=V1))+
  geom_histogram(aes(y=..density..),binwidth=1,fill="darkgray")



binomialN<-function(p,r){
  u<-runif(r)
  g<-floor(log(u)/log(1-p))+1
  return(sum(g))
}

# primeros 10 valores de la binomial negativa
set.seed(221285)
r=20
p=0.4
sim1<-rdply(10,binomialN(p,r))$V1
sim1
```


<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\hist4b.png)

De tal manera que para generar varaibles aleatorias con distribución binomial negativa, tenemos que generar $r$ variables uniformes y sumarlas. Las primeras $10$ realizaciones son las siguientes:

| $bn_1$ | $bn_2$ | $bn_3$ | $bn_4$ | $bn_5$ | $bn_6$ | $bn_7$ | $bn_8$ | $bn_9$ | $bn_{10}$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:-------:|
|   44   |   57   |   48   |   39   |   45   |   50   |   50   |   39   |   56   |    42   |

#### c) Verifica la relación
 $$p_{j+1}=\frac{j(1-p)}{j+1-r}p_j$$
 
#### y úsala para generar un nuevo algoritmo de simulación, vuelve a definir la semilla y reporta las primeras 10 simulaciones.

A partir de la relación
$$p_{j+1}=\frac{j(1-p)}{j+1-r}p_j$$
se pueden generar variables aleatorias distribuidas binomial negativa, sin embargo, es necesario conocer cuál es la probabilidad inicial para que este algoritmo pueda empezar a iterar. En este caso, la parametrización de la binomial negativa se define como el número de ensayos necesarios para alcanzar $r$ éxitos, por lo que su soporte inicia en $20$ de tal manera que se tiene que $r=20$ y por lo tanto $p(x=20)= 0.4^{20}$ y a partir de ésta, comenzar la iteración.

Así pues, a partir de la probabilidad acumulada se puede obtener el entero tal que acumule dicha probabilidad. Este valor entero será una realización de una binomial negativa. 

```{r,eval=FALSE}

set.seed(221285)
binoneg=function(p,r) {
u<-runif(1)
j<-20
x<-j
prob<-p**r
acum<-prob
while(u>acum){
  prob<-j/(j-r+1)*(1-p)*prob
  acum<-acum+prob
  x<-j
  j<-j+1
}
return(x)
}

set.seed(221285)
sim2<-rdply(10,binoneg(p=0.4,r=20))$V1
sim2

set.seed(221285)
rnbinom(10,r,p)

```

Las primeras $10$ realizaciones con este nuevo algoritmo son:

| $bn_1$ | $bn_2$ | $bn_3$ | $bn_4$ | $bn_5$ | $bn_6$ | $bn_7$ | $bn_8$ | $bn_9$ | $bn_{10}$ |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:-------:|
|   66   |   44   |   53   |   40   |   54   |   56   |   45   |   71   |   43   |    54   |


#### d) Realiza 10,000 simulaciones usando cada uno de los algoritmos y compara el tiempo de ejecución.

La información del tiempo de ejecución para los métodos son:

|          | user | system | elapsed |
|----------|------|--------|---------|
| Método 1 | 1.08 | 0.00   | 1.08    |
| Método 2 | 2.72 | 0.00   | 2.71    |

Por lo que es posible apreciar que el método 2 es más lento que el primero.

#### e) Genera un histogrma para cada algoritmo (usa 1000 simulaciones) y comparalo con la distribución construida usando la función de R _dnbinom_.

Para generar variables aleatorias con distribución binomial negativa a partir de la función de R _dnbinom_ es necesario comentar que la parametrización de esta variable es diferente a la considerada en presente trabajo, la diferencia en ambas radica basicamente en el soporte que consideran, pues el soporte de la parametrización que considera _dnbinom_ comienza en cero mientras que en la presentada anteriormente comienza en $r=20$. Por esta razón basta con sumarle $20$ a los valores arrojados por la función de R para que muestren el mismo soporte.

```{r,eval=FALSE}
set.seed(221285)
m1<-rdply(1000,binomialN(0.4,20))$V1
set.seed(221285)
m2<- rdply(1000,binoneg(0.4,20))$V1
set.seed(221285)
rbin<-rnbinom(1000,size=20,prob=0.4)+20

#devtools::install_github("hadley/tidyr")
datos<-data.frame(Metodo1=m1,R=rbin)
datos1<-gather(datos,metodo,var)
ggplot(datos1, aes(var, fill = metodo)) + geom_histogram(alpha = 0.7, aes(y = ..density..), position = 'identity')

datos<-data.frame(Metodo2=m2,R=rbin)
datos1<-gather(datos,metodo,var)
ggplot(datos1, aes(var, fill = metodo)) + geom_histogram(alpha = 0.7, aes(y = ..density..), position = 'identity')

```

Observemos el desempeño del primer método 
<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\met1vsr.png)

Ahora veamos el desempeño del segundo método

<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\met2vsr.png)

Es posible notar que ambos métodos funcionan adecuadamente.


## Pregunta 5

Cobertura de intervalos de confianza. En este problema realizarás un ejercicio de simulación para comparar intervalos de confianza. Utiliza la función _rnorm_ (y la semilla 221285) para simular muestras de tamaño 10 de una distribución normal estándar, el estadístico de interés es  $\theta=exp(\mu)$. También es de nuestro interés generar simulaciones de muestras de tamaño 20 de una distribución Poisson con parámetro $\lambda = 2.5$ y estadí?stico de interés $\theta = exp(-2\lambda)$.

Sigue el siguiente proceso:

i) Genera una muestra aleatoria de una distribución normal estándar de tamaño 10.

ii) Genera 6000 muestras bootstrap y calcula intervalos de confianza del 95\% para $\hat{\theta}$ usando 1) el método normal, 2) percentiles y 3) BC_a.

iii) Revisa si el intervalo de confianza contiene el verdadero valor del parámetro ($\theta=1$), en caso de que no lo contenga registra si falló por la izquierda (el lí?mite inferior >1)o falló por la derecha(el lí?mite superior <1).

#### a) Repite el proceso descrito 500 veces y llena la siguiente tabla:


El código para el estadístico  $\theta=exp(\mu)$ es:
```{r,eval=FALSE}

set.seed(221285)
muestra<-rnorm(10)

theta<-exp(mean(muestra))

thetaboot<-function(x){
  n<-length(x)
  x_boot <- sample(x, n, replace = TRUE)
  return(exp(mean(x_boot)))
}

B <- 6000
theta_b <- rdply(B, thetaboot(muestra))
li_normal <- round(theta - 1.96 * sd(theta_b$V1), 2)
ls_normal <- round(theta + 1.96 * sd(theta_b$V1), 2)
c(li_normal,ls_normal) #intervalos normales


ggplot(theta_b, aes(x = V1)) + 
  geom_histogram(binwidth = 0.05, fill = "gray30") +
  geom_vline(xintercept = c(li_normal, ls_normal, theta), 
             color = c("black", "black", "red"))


# percentiles
ls_per <- round(quantile((theta_b$V1), prob = 0.975), 2)
li_per <- round(quantile((theta_b$V1), prob = 0.025), 2)
c(li_per,ls_per)

#bca
# definimos la funcion necesaria para utilizar boot
set.seed(221285)
theta_est<-function(data,indices){
  d<-data[indices,]
  theta<-exp(mean(d))
return(theta)
}

#la funcion boot usa la funcion anterior en la que se definio el estadistico de interes
# para el cual se desea conocer el intervalo de confianza
theta_boot<-boot(data=as.data.frame(muestra),statistic=theta_est,R=6000)
bca<-boot.ci(theta_boot,statistic=theta_est,type="bca",index=1)
bca_ci<-round(bca$bca[4:5],2)

c(li_normal,ls_normal)
c(li_per,ls_per)
bca_ci
# en los tres casos se encuentra el valor real theta=1
# en la normal el interavlo no es bueno pues la distribuicon es asimetrica
# mientras que los de percentiles y bca son similares debido a que el primera
# considera la distribucion acumulada unicamente y el segundo realiza una 
# correccion por sesgo

# los intervalos de confianza normales podrian mejorarse si se aplicara la funcion inversa
# que normalice la distribucion del estadistico



# proceso para comparar los tres intervalos de confianza estimados, en el cual se pretende observar
# si incluyen al valor real, si hay fallo por la izquierda o fallo por la derecha


n<-500
fi_n<-0
fi_p<-0
fi_bca<-0
fd_n<-0
fd_p<-0
fd_bca<-0
cob_n<-0
cob_p<-0
cob_bca<-0
li_normal<-rep(0,n)
ls_normal<-rep(0,n)
li_per<-rep(0,n)
ls_per<-rep(0,n)
li_bca<-rep(0,n)
ls_bca<-rep(0,n)
theta<-rep(0,n)

set.seed(221285)

for(i in 1:n){
  # para medias

  muestra<-rnorm(10)
  theta[i]<-exp(mean(muestra))
  theta_b <- rdply(6000, thetaboot(muestra))
  
  # se calcula el intervalo de confiaza normal
  li_normal[i] <- theta[i] - 1.96 * sd(theta_b$V1)
  ls_normal[i] <- theta[i] + 1.96 * sd(theta_b$V1)
  
  # se calcula el intervalo de confianza por percentiles
  ls_per[i] <- as.numeric(quantile((theta_b$V1), prob = 0.975))
  li_per[i] <- as.numeric(quantile((theta_b$V1), prob = 0.025))
  
  # se calcula el intervalo de confianza por bca
  theta_boot<-boot(data=as.data.frame(muestra),statistic=theta_est,R=6000)
  bca<-boot.ci(theta_boot,statistic=theta_est,type="bca",index=1)
  bca_ci<-bca$bca[4:5]
  li_bca[i]<-bca_ci[1]
  ls_bca[i]<-bca_ci[2]  
  
}


datos_ic<-data.frame(theta,li_normal,ls_normal,li_per,ls_per,li_bca,ls_bca)

cob_normal<-sum(datos_ic$li_normal<=1 & datos_ic$ls_normal>=1)
cob_per<-sum(datos_ic$li_per<=1 & datos_ic$ls_per>=1)
cob_bca<-sum(datos_ic$li_bca<=1 & datos_ic$ls_bca>=1)

fi_normal<-sum(datos_ic$li_normal>1)
fi_per<-sum(datos_ic$li_per>1)
fi_bca<-sum(datos_ic$li_bca>1)

fd_normal<-sum(datos_ic$ls_normal<1)
fd_per<-sum(datos_ic$ls_per<1)
fd_bca<-sum(datos_ic$ls_bca<1)


tabla<-data.frame(fizq=c(fi_normal,fi_per,fi_bca),fder=c(fd_normal,fd_per,fd_bca),cob=c(cob_normal,cob_per,cob_bca))
tabla_p<-(tabla/n)*100



coef_df<- datos_ic %>%
  gather(metodo,limite,-theta) %>%
  separate(metodo,c("int","metodo"),3) %>%
  mutate(lim=substr(int,1,2))%>%
  select(-int) %>%
  spread(lim,limite) %>%
  mutate(ind=rep(1:n, each=3)) 



ggplot(coef_df, aes(x = ind, y = theta, ymin = li, 
                    ymax= ls)) +
  geom_pointrange(size = 0.4) + 
  facet_wrap(~ metodo, scales = "free_y", nrow = 3) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7))+
  geom_hline(yintercept=1,color="red")

```

El código para el estadístico $\theta = exp(-2\lambda)$ es:
```{r,eval=FALSE}


set.seed(221285)
muestra<-rpois(20,2.5)
theta<-exp(-2*mean(muestra))

thetaboot<-function(x){
  n<-length(x)
  x_boot <- sample(x, n, replace = TRUE)
  return(exp(-2*mean(x_boot)))
}

B <- 6000
theta_b <- rdply(B, thetaboot(muestra))
li_normal <-theta - 1.96 * sd(theta_b$V1)
ls_normal <-theta + 1.96 * sd(theta_b$V1)
c(li_normal,ls_normal) #intervalos normales


ggplot(theta_b, aes(x = V1)) + 
  geom_histogram(binwidth = 0.005, fill = "gray30") +
  geom_vline(xintercept = c(li_normal, ls_normal, theta), 
             color = c("black", "black", "red"))


# percentiles
ls_per <- quantile((theta_b$V1), prob = 0.975)
li_per <- quantile((theta_b$V1), prob = 0.025)
c(li_per,ls_per)

#bca
# definimos la funcion necesaria para utilizar boot
set.seed(221285)
theta_est<-function(data,indices){
  d<-data[indices,]
  theta<-exp(-2*mean(d))
  return(theta)
}

#la funcion boot usa la funcion anterior en la que se definio el estadistico de interes
# para el cual se desea conocer el intervalo de confianza
theta_boot<-boot(data=as.data.frame(muestra),statistic=theta_est,R=6000)
bca<-boot.ci(theta_boot,statistic=theta_est,type="bca",index=1)
bca_ci<-bca$bca[4:5]

c(li_normal,ls_normal)
c(li_per,ls_per)
bca_ci



n<-500
fi_n<-0
fi_p<-0
fi_bca<-0
fd_n<-0
fd_p<-0
fd_bca<-0
cob_n<-0
cob_p<-0
cob_bca<-0
li_normal<-rep(0,n)
ls_normal<-rep(0,n)
li_per<-rep(0,n)
ls_per<-rep(0,n)
li_bca<-rep(0,n)
ls_bca<-rep(0,n)
theta<-rep(0,n)
set.seed(221285)
for(i in 1:n){
  # para medias
  muestra<-rpois(20,2.5)
  theta[i]<-exp(-2*mean(muestra))
  theta_b <- rdply(6000, thetaboot(muestra))
  
  # se calcula el intervalo de confiaza normal
  li_normal[i] <- theta[i] - 1.96 * sd(theta_b$V1)
  ls_normal[i] <- theta[i] + 1.96 * sd(theta_b$V1)
  
  # se calcula el intervalo de confianza por percentiles
  ls_per[i] <- as.numeric(quantile((theta_b$V1), prob = 0.975))
  li_per[i] <- as.numeric(quantile((theta_b$V1), prob = 0.025))
  
  # se calcula el intervalo de confianza por bca
  theta_boot<-boot(data=as.data.frame(muestra),statistic=theta_est,R=6000)
  bca<-boot.ci(theta_boot,statistic=theta_est,type="bca",index=1)
  bca_ci<-bca$bca[4:5]
  li_bca[i]<-bca_ci[1]
  ls_bca[i]<-bca_ci[2]  
  
}


datos_ic<-data.frame(theta,li_normal,ls_normal,li_per,ls_per,li_bca,ls_bca)

real<-exp(-2*2.5)

cob_normal<-sum(datos_ic$li_normal<=real & datos_ic$ls_normal>=real)
cob_per<-sum(datos_ic$li_per<=real & datos_ic$ls_per>=real)
cob_bca<-sum(datos_ic$li_bca<=real & datos_ic$ls_bca>=real)

fi_normal<-sum(datos_ic$li_normal>real)
fi_per<-sum(datos_ic$li_per>real)
fi_bca<-sum(datos_ic$li_bca>real)

fd_normal<-sum(datos_ic$ls_normal<real)
fd_per<-sum(datos_ic$ls_per<real)
fd_bca<-sum(datos_ic$ls_bca<real)


tabla<-data.frame(fizq=c(fi_normal,fi_per,fi_bca),fder=c(fd_normal,fd_per,fd_bca),cob=c(cob_normal,cob_per,cob_bca))
tabla_p<-(tabla/n)*100


coef_df<- datos_ic %>%
  gather(metodo,limite,-theta) %>%
  separate(metodo,c("int","metodo"),3) %>%
  mutate(lim=substr(int,1,2))%>%
  select(-int) %>%
  mutate(ind=rep(1:n,times=6)) %>%
  spread(lim,limite) %>%
  arrange(metodo) %>%
  select(-ind) %>%
  mutate(ind=rep(1:n, times=3))
  
  
ggplot(coef_df, aes(x = ind, y = theta, ymin = li, 
                    ymax= ls)) +
  geom_pointrange(size = 0.4) + 
  facet_wrap(~ metodo, scales = "free_y", nrow = 3) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7)) +
  geom_hline(yintercept=real,color="red")
```




La tabla de resumen para los intervalos de confianza del estadístico de interés $\theta=exp(\mu)$

|           | fallo izq | fallo der | cobertura |
|:---------:|:---------:|:---------:|:---------:|
|   normal  |     9     |     43    |    448    |
| percentil |     26    |     24    |    450    |
|    bca    |     26    |     23    |    451    |

La tabla de resumen para los intervalos de confianza del estadístico de interés  $\theta = exp(-2\lambda)$

|           | fallo izq | fallo der | cobertura |
|:---------:|:---------:|:---------:|:---------:|
|   normal  |     0     |     40    |    460    |
| percentil |     10    |     17    |    473    |
|    bca    |     6     |     22    |    472    |


#### b) Realiza una gráfica de páneles, en cada panel mostrarás los resultados de uno de los métodos (normal, percentiles, BCa), el eje x corresponderá al número de intervalo de confianza ($1,\cdots,500$) y el vertical graficarás los limites de los intervalos, es decir graficaras 2 lineas(usa geom_line) una corresponderá al los limites inferiores de los intervalos y otra a los superiores.


En la gráfica de páneles para el primer estadístico muestra en el eje x las iteraciones, sin embargo, se muestran ordenadas respecto al valor del estadístico, de esta manera es posible observar más claramente el fallo por la derecha y el fallo por la izquierda.

<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\exp_ci.jpeg)

intervalos de confianza para el estadístico $\theta=exp(\mu)$. </center>



Por el contrario en la gráfica de páneles del segundo estadístico refuerza lo evidenciado en la tabla de resumen de los intervalos pues para este estadístico se tienen más fallos por la derecha que por la izquierda.


<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\pois_ci.jpeg) 

intervalos de confianza para el estadístico $\theta = exp(-2\lambda)$. </center>


## Pregunta 6

En la carpeta datos encontrarás un excel llamado Cuadros_2010 que contiene información de migración en México, para más información de los datos visita la sección de [migración interna](http://www.conapo.gob.mx/es/CONAPO/Migracion _Interna) de CONAPO. Cada pestaña contiene información de migración distinta (relativa a salarios, edad, géner, etc.) elige una tabla (pestaña) y realiza lo siguiente:

#### a) Lee los datos en R, ¿Cumplen los principios de datos limpios? Si tu respuesta es negativa explica las razones por las que no los cumples y _limpialos_.


Los datos mostrados en la pestaña de PEA (población economicamente activa) no cumplen con los principios de datos limpios pues no se tiene el caso en el que cada columna representa a una varable, sino que se tiene algo similar a una tabla cruzada con más de dos niveles. Además, por la misma estructura antes mencionada no es posible decir que cada renglón forma una observación. El hecho de tener la información de esta manera complica el análisis estadístico ya que representa una mayor complejidad su manipulación, así como la creación de gráficos descriptivos y por supuesto, se complica la aplicación de cualquier tipo de modelo estadístico.

#### b) Escribe al menos una pregunta que puedas responder con estos datos y genera al menos una gráfica que te ayude a contestarla o entenderla mejor


¿La población migrante representa una parte importante de la población económicamente activa de las entidades federativas en términos de porcentaje relativo? 

<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\Rplot2.png)</center>

Como se puede observar en la gráfica, la población migrante ocupa un peso importante en la población económicamente activa dentro de las entidades federativas, es decir, la mayoría de los migrantes en cada estado de la república mexicana participan en el sumarizado de la PEA. Por el contrario, esta distinción se hace ambigua para los no migrantes pues la proporción de población activa e inactiva es muy similar.

También se puede observar en la siguiente gráfica, la cual muestra que de la población económicamente activa, los migrantes ocupan un mayor porcentaje relativo que los no migrantes.

<center>![Rplot2](C:\Users\Administrador\Desktop\parcialEC\imagenes\Rplot4.png)</center>








